{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cfb6fd2-0fc7-447d-b1bd-d6d13db7489b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#importacao\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import IntegerType, DoubleType, TimestampType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.sql.functions import year, month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d304379f-8464-421a-8ffb-64f4f78ed164",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Leitura do delta lake ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61ef7240-edcb-43da-ab08-e00ca5b1beb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_janeiro = spark.read.parquet(\"s3://bucket-taxi-project/raw/yellow_tripdata_2023-01.parquet\")\n",
    "\n",
    "df_janeiro = df_janeiro.select(\n",
    "    col(\"VendorID\").cast(IntegerType()),\n",
    "    col(\"passenger_count\").cast(IntegerType()),\n",
    "    col(\"total_amount\").cast(DoubleType()),\n",
    "    col(\"tpep_pickup_datetime\").cast(TimestampType()),\n",
    "    col(\"tpep_dropoff_datetime\").cast(TimestampType())\n",
    ").na.drop(subset=[\"VendorID\", \"passenger_count\", \"total_amount\", \n",
    "                  \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"])\n",
    "\n",
    "#  Criar colunas de ano e mês para particionamento\n",
    "df_janeiro = df_janeiro.withColumn(\"year\", year(col(\"tpep_pickup_datetime\"))) \\\n",
    "                 .withColumn(\"month\", month(col(\"tpep_pickup_datetime\")))\n",
    "\n",
    "# Salvar já particionado por ano e mês\n",
    "df_janeiro.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"year\", \"month\") \\\n",
    "    .save(\"s3a://bucket-taxi-project/bronze/yellow_janeiro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "811c03b9-2f60-46c5-ba2f-fb4c1d6306f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_fevereiro = spark.read.parquet(\"s3://bucket-taxi-project/raw/yellow_tripdata_2023-02.parquet\")\n",
    "\n",
    "df_fevereiro = df_fevereiro.select(\n",
    "    col(\"VendorID\").cast(IntegerType()),\n",
    "    col(\"passenger_count\").cast(IntegerType()),\n",
    "    col(\"total_amount\").cast(DoubleType()),\n",
    "    col(\"tpep_pickup_datetime\").cast(TimestampType()),\n",
    "    col(\"tpep_dropoff_datetime\").cast(TimestampType())\n",
    ").na.drop(subset=[\"VendorID\", \"passenger_count\", \"total_amount\", \n",
    "                  \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"])\n",
    "\n",
    "#  Criar colunas de ano e mês para particionamento\n",
    "df_fevereiro = df_fevereiro.withColumn(\"year\", year(col(\"tpep_pickup_datetime\"))) \\\n",
    "                 .withColumn(\"month\", month(col(\"tpep_pickup_datetime\")))\n",
    "\n",
    "# Salvar já particionado por ano e mês\n",
    "df_fevereiro.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"year\", \"month\") \\\n",
    "    .save(\"s3a://bucket-taxi-project/bronze/yellow_fevereiro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dac5d5ce-aa3f-4b47-9f8e-e4c543c01049",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_marco = spark.read.parquet(\"s3://bucket-taxi-project/raw/yellow_tripdata_2023-03.parquet\")\n",
    "\n",
    "df_marco = df_marco.select(\n",
    "    col(\"VendorID\").cast(IntegerType()),\n",
    "    col(\"passenger_count\").cast(IntegerType()),\n",
    "    col(\"total_amount\").cast(DoubleType()),\n",
    "    col(\"tpep_pickup_datetime\").cast(TimestampType()),\n",
    "    col(\"tpep_dropoff_datetime\").cast(TimestampType())\n",
    ").na.drop(subset=[\"VendorID\", \"passenger_count\", \"total_amount\", \n",
    "                  \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"])\n",
    "                  \n",
    "#  Criar colunas de ano e mês para particionamento\n",
    "df_marco = df_marco.withColumn(\"year\", year(col(\"tpep_pickup_datetime\"))) \\\n",
    "                 .withColumn(\"month\", month(col(\"tpep_pickup_datetime\")))\n",
    "\n",
    "# Salvar já particionado por ano e mês\n",
    "df_marco.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"year\", \"month\") \\\n",
    "    .save(\"s3a://bucket-taxi-project/bronze/yellow_marco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e84020be-3b8a-48ae-b7f5-1f2f3d73110f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_abril = spark.read.parquet(\"s3://bucket-taxi-project/raw/yellow_tripdata_2023-04.parquet\")\n",
    "\n",
    "df_abril = df_abril.select(\n",
    "    col(\"VendorID\").cast(IntegerType()),\n",
    "    col(\"passenger_count\").cast(IntegerType()),\n",
    "    col(\"total_amount\").cast(DoubleType()),\n",
    "    col(\"tpep_pickup_datetime\").cast(TimestampType()),\n",
    "    col(\"tpep_dropoff_datetime\").cast(TimestampType())\n",
    ").na.drop(subset=[\"VendorID\", \"passenger_count\", \"total_amount\", \n",
    "                  \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"])\n",
    "#  Criar colunas de ano e mês para particionamento\n",
    "df_abril = df_abril.withColumn(\"year\", year(col(\"tpep_pickup_datetime\"))) \\\n",
    "                 .withColumn(\"month\", month(col(\"tpep_pickup_datetime\")))\n",
    "\n",
    "# Salvar já particionado por ano e mês\n",
    "df_abril.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"year\", \"month\") \\\n",
    "    .save(\"s3a://bucket-taxi-project/bronze/yellow_abril\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d884d785-5fff-499d-b6b7-5d845ba51a41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_maio = spark.read.parquet(\"s3://bucket-taxi-project/raw/yellow_tripdata_2023-05.parquet\")\n",
    "\n",
    "df_maio = df_maio.select(\n",
    "    col(\"VendorID\").cast(IntegerType()),\n",
    "    col(\"passenger_count\").cast(IntegerType()),\n",
    "    col(\"total_amount\").cast(DoubleType()),\n",
    "    col(\"tpep_pickup_datetime\").cast(TimestampType()),\n",
    "    col(\"tpep_dropoff_datetime\").cast(TimestampType())\n",
    ").na.drop(subset=[\"VendorID\", \"passenger_count\", \"total_amount\", \n",
    "                  \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"])\n",
    "\n",
    "#  Criar colunas de ano e mês para particionamento\n",
    "df_maio = df_maio.withColumn(\"year\", year(col(\"tpep_pickup_datetime\"))) \\\n",
    "                 .withColumn(\"month\", month(col(\"tpep_pickup_datetime\")))\n",
    "\n",
    "# Salvar já particionado por ano e mês\n",
    "df_maio.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"year\", \"month\") \\\n",
    "    .save(\"s3a://bucket-taxi-project/bronze/yellow_maio\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ingest_taxi_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
